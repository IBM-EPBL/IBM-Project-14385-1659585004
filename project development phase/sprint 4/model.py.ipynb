{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": "import pandas as pd\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nimport seaborn as sns\nimport numpy as np\nfrom imblearn.combine import SMOTETomek\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nloan_data = pd.read_csv(r'C:\\Users\\bhaav\\OneDrive\\Desktop\\My_Projects_DS\\LoanDataset.csv')\n\n\n\"\"\"## EDA\n\n## Uni variate Analysis\n\"\"\"\n\nplt.figure(figsize=(20, 12))\nplt.subplot(231)\nsns.distplot(loan_data['ApplicantIncome'], color='r')\nplt.subplot(232)\nsns.distplot(loan_data['Credit_History'])\nplt.subplot(233)\nsns.distplot(loan_data['CoapplicantIncome'], color='r')\nplt.subplot(234)\nsns.distplot(loan_data['LoanAmount'])\nplt.subplot(235)\nsns.distplot(loan_data['Loan_Amount_Term'], color='r')\n# plt.show()\n\nplt.figure(figsize=(12, 4))\nplt.subplot(121)\nsns.countplot(loan_data['Gender'])\nplt.subplot(122)\nsns.countplot(loan_data['Education'])\n# plt.show()\n\nplt.figure(figsize=(20, 5))\nplt.subplot(131)\nsns.countplot(loan_data['Gender'], hue=loan_data['Education'])\nplt.subplot(132)\nsns.countplot(loan_data['Married'], hue=loan_data['Gender'])\nplt.subplot(133)\nsns.countplot(loan_data['Self_Employed'], hue=loan_data['Education'])\n# plt.show()\nplt.figure(figsize=(20, 10))\nsns.countplot(loan_data['Property_Area'], hue=loan_data['Loan_Amount_Term'])\n# plt.show()\n\ntemp_data = loan_data.drop(\n    ['Loan_ID', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Loan_Status'], axis=1)\ncols = temp_data.columns\nfor c in cols:\n    plt.figure(c, figsize=(7, 4))\n    sns.countplot(temp_data[c], hue=loan_data['Loan_Status'])\n\n# plt.show()\n\nloan_data['ApplicantIncome'].max()\nmaximum_income = loan_data['ApplicantIncome'].unique().max()\nminimum_income = loan_data['ApplicantIncome'].unique().min()\nprint(maximum_income, minimum_income)\n\nloan_data['CoapplicantIncome'].max()\nmaximum_income = loan_data['CoapplicantIncome'].unique().max()\nminimum_income = loan_data['CoapplicantIncome'].unique().min()\nprint(maximum_income, minimum_income)\n\ncopy_data = loan_data.copy()\nbin_range = [150, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 81000]\ncopy_data['Income_group'] = pd.cut(x=copy_data['ApplicantIncome'], bins=bin_range)\ncopy_data['Income_group'].value_counts()\n\nplt.figure(figsize=(20, 5))\nsns.countplot(x=copy_data['Income_group'], hue=copy_data['Loan_Status'])\n# plt.show()\n\nbin_range = [1, 10000, 20000, 30000, 42000]\ncopy_data['CoIncome_group'] = pd.cut(x=copy_data['CoapplicantIncome'], bins=bin_range)\ncopy_data['CoIncome_group'].value_counts()\n\nplt.figure(figsize=(20, 5))\nsns.countplot(x=copy_data['CoIncome_group'], hue=copy_data['Loan_Status'])\n# plt.show()\n\n\"\"\"### Multivariate Analysis\"\"\"\n\nsns.swarmplot(loan_data['Gender'], loan_data['ApplicantIncome'], hue=loan_data['Loan_Status'])\n\n\"\"\"### Descriptive Analysis\"\"\"\n\nloan_data.describe()\n\nstat_data = loan_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']]\nfor i in stat_data:\n    plt.hist(loan_data[i])\n    # plt.show()\n\n\"\"\"## Data Preprocessing\"\"\"\n\nloan_data = loan_data.drop(columns=['Loan_ID'], axis=1)\nloan_data.head()\n\n\"\"\"## Handling Missing Values\"\"\"\n\nloan_data.isna()\n\nnull_data = loan_data.isna().sum()\nnull_data.sort_values()\n\nmsno.bar(loan_data)\n\nmsno.matrix(loan_data)\n\nunique_cols = loan_data.drop(['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount'], axis=1)\nfor col in unique_cols:\n    print(col, loan_data[col].unique())\n\nloan_data['Gender'] = loan_data['Gender'].fillna(loan_data['Gender'].mode()[0])\nloan_data['Married'] = loan_data['Married'].fillna(loan_data['Married'].mode()[0])\nloan_data['Dependents'] = loan_data['Dependents'].str.replace('+', '')\nloan_data['Self_Employed'] = loan_data['Self_Employed'].fillna(loan_data['Self_Employed'].mode()[0])\nloan_data['LoanAmount'] = loan_data['LoanAmount'].fillna(loan_data['LoanAmount'].mode()[0])\nloan_data['Loan_Amount_Term'] = loan_data['Loan_Amount_Term'].fillna(loan_data['Loan_Amount_Term'].mode()[0])\nloan_data['Credit_History'] = loan_data['Credit_History'].fillna(loan_data['Credit_History'].mode()[0])\n# loan_data\n\nloan_data['CoapplicantIncome'] = loan_data['CoapplicantIncome'].astype('int64')\nloan_data['LoanAmount'] = loan_data['LoanAmount'].astype('int64')\nloan_data['Loan_Amount_Term'] = loan_data['Loan_Amount_Term'].astype('int64')\nloan_data['Credit_History'] = loan_data['Credit_History'].astype('int64')\n# loan_data\n\nlabel_encoder = preprocessing.LabelEncoder()\nlabel_encoding_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area',\n                          'Loan_Status']\nfor col in label_encoding_columns:\n    loan_data[col] = label_encoder.fit_transform(loan_data[col])\n\n# loan_data\n\nsmk = SMOTETomek(0.90)\n\ny = loan_data['Loan_Status']\nx = loan_data.drop(columns=['Loan_Status'], axis=1)\n\nx_bal, y_bal = smk.fit_resample(x, y)\nprint(y.value_counts())\nprint(y_bal.value_counts())\n\nsc = StandardScaler()\nx_bal = sc.fit_transform(x_bal)\nx_bal = pd.DataFrame(x_bal)\n\n# loan_data\n\nX_train, X_test, y_train, y_test = train_test_split(x_bal, y_bal, test_size=0.33, random_state=42)\n\n\"\"\"## MODEL BUILDING\"\"\"\n\nacc = {}\n\n\ndef Decision_Tree(X_train, X_test, y_train, y_test):\n    dt = DecisionTreeClassifier()\n    dt.fit(X_train, y_train)\n\n    # predicting the outcome\n    y_pred = dt.predict(X_test)\n    print(\"Confusion Matrix\")\n    cm = confusion_matrix(y_test, y_pred)\n    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n    cm_display.plot()\n    # plt.show()\n    print(\"Classification Report\")\n    cr = classification_report(y_test, y_pred)\n    print(cr)\n    acc['Decision Tree Classifier'] = accuracy_score(y_test, y_pred)\n\n\nDecision_Tree(X_train, X_test, y_train, y_test)\n\n\ndef Random_Forest(X_train, X_test, y_train, y_test):\n    rf = RandomForestClassifier()\n    rf.fit(X_train, y_train)\n\n    # predicting the outcome\n    y_pred = rf.predict(X_test)\n    print(\"Confusion Matrix\")\n    cm = confusion_matrix(y_test, y_pred)\n    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n    cm_display.plot()\n    # plt.show()\n    print(\"Classification Report\")\n    cr = classification_report(y_test, y_pred)\n    print(cr)\n    acc['Random Forest Classifier'] = accuracy_score(y_test, y_pred)\n\n\nRandom_Forest(X_train, X_test, y_train, y_test)\n\n\ndef KNN(X_train, X_test, y_train, y_test):\n    knn = KNeighborsClassifier()\n    knn.fit(X_train, y_train)\n\n    # predicting the outcome\n    y_pred = knn.predict(X_test)\n    print(\"Confusion Matrix\")\n    cm = confusion_matrix(y_test, y_pred)\n    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n    cm_display.plot()\n    # plt.show()\n    print(\"Classification Report\")\n    cr = classification_report(y_test, y_pred)\n    print(cr)\n    acc['KNN'] = accuracy_score(y_test, y_pred)\n\n\nKNN(X_train, X_test, y_train, y_test)\n\n\ndef XGboost(X_train, X_test, y_train, y_test):\n    xg = GradientBoostingClassifier()\n    xg.fit(X_train, y_train)\n\n    # predicting the outcome\n    y_pred = xg.predict(X_test)\n    print(\"Confusion Matrix\")\n    cm = confusion_matrix(y_test, y_pred)\n    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n    cm_display.plot()\n    # plt.show()\n    print(\"Classification Report\")\n    cr = classification_report(y_test, y_pred)\n    print(cr)\n    acc['Gradient Boost'] = accuracy_score(y_test, y_pred)\n\n\nXGboost(X_train, X_test, y_train, y_test)\nxg = GradientBoostingClassifier()\nxg.fit(X_train, y_train)\n\n# input_feature = [1,1,1,1,1,5849,1508,120,360,1,1]\ninput_feature = ['Female', 'Yes', 0, 'Graduate', 'Yes', 584900, 0, 120, 360, 1, 'Urban']\ninput_feature = [np.array(input_feature)]\nprint(input_feature)\nnames = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome',\n         'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']\ndata = pd.DataFrame(input_feature, columns=names)\nprint(data)\nnew = data.copy()\nlabel_encoder = preprocessing.LabelEncoder()\nlabel_encoding_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\nfor col in label_encoding_columns:\n    new[col] = label_encoder.fit_transform(new[col])\npreed = xg.predict(new)\nprint(preed)\nprint(acc)\n\n# import pickle\n#\n# xg = GradientBoostingClassifier()\n# xg.fit(X_train, y_train)\n# # save the model to disk\n# pickle.dump(xg, open('model3.pkl','wb'))\n#\n# model = pickle.load(open('model3.pkl','rb'))\n#\n# print(model.predict(X_test))",
      "metadata": {}
    }
  ]
}